{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell jupyter where pyspark is\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ALS and Linear Regression models\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "### Data Preparation\n",
    "The dataset I found contains 515,000 customer reviews and scoring of 1493 luxury hotels across Europe. The columns of the dataset contains:\n",
    "\n",
    "(1)Hotel_Address: Address of hotel.\n",
    "\n",
    "(2)Review_Date: Date when reviewer posted the corresponding review.\n",
    "\n",
    "(3)Average_Score: Average Score of the hotel, calculated based on the latest comment in the last year.\n",
    "\n",
    "(4)Hotel_Name: Name of Hotel.\n",
    "\n",
    "(5)Reviewer_Nationality: Nationality of Reviewer.\n",
    "\n",
    "(6)Negative_Review: Negative Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Negative'.\n",
    "\n",
    "(7)Review_Total_Negative_Word_Counts: Total number of words in the negative review.\n",
    "\n",
    "(8)Positive_Review: Positive Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Positive'.\n",
    "\n",
    "(9)Review_Total_Positive_Word_Counts: Total number of words in the positive review.\n",
    "\n",
    "(10)Reviewer_Score: Score the reviewer has given to the hotel, based on his/her experience.\n",
    "\n",
    "(11)Total_Number_of_Reviews_Reviewer_Has_Given: Number of Reviews the reviewers has given in the past.\n",
    "\n",
    "(12)Total_Number_of_Reviews: Total number of valid reviews the hotel has.\n",
    "\n",
    "(13)Tags: Tags reviewer gave the hotel.\n",
    "\n",
    "(14)days_since_review: Duration between the review date and scrape date.\n",
    "\n",
    "(15)Additional_Number_of_Scoring: There are also some guests who just made a scoring on the service rather than a review. This number indicates how many valid scores without review in there.\n",
    "\n",
    "(16)lat: Latitude of the hotel.\n",
    "\n",
    "(17)lng: longtitude of the hotel.\n",
    "\n",
    "Now, we want to make a recommendation algorithm to recommend the most appropriate hotel for a customer if we know his/her nationality and days to stay in the hotel. Therefore, we will use hotel name to generate productID. However, for userID, we would combine the nationality and days for staying in the hotel to generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a SparkSession\n",
    "# SparkSession provides a single point of entry to interact with underlying Spark functionality\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"ALSExample\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "import csv\n",
    "import numpy as np\n",
    "with open('/Users/jbian/Downloads/hotel_reviews.csv', 'r') as f:\n",
    "    hotels = list(csv.reader(f, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "515534\n",
      "515534\n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "\n",
    "stay_days = []\n",
    "i_list = []\n",
    "for i in range(1,len(hotels)):\n",
    "    if 'Stayed' in hotels[i][-4]:\n",
    "        a = hotels[i][-4][hotels[i][-4].find(\"Stayed\")+6:hotels[i][-4].find(\" night\")]\n",
    "        if a != '':\n",
    "            stay_days.append(int(a))\n",
    "            i_list.append(i)\n",
    "print(max(stay_days))\n",
    "print(len(stay_days))\n",
    "print(len(i_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515534\n"
     ]
    }
   ],
   "source": [
    "hotel = list( hotels[i] for i in i_list)\n",
    "print(len(hotel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "\n",
    "import math\n",
    "name = []\n",
    "nat = []\n",
    "for i in range(1,len(hotel)):\n",
    "    if hotel[i][4] not in name:\n",
    "        name.append(hotel[i][4])\n",
    "        hotel[i][4] = len(name)\n",
    "    else:\n",
    "        num = [j+1 for j,x in enumerate(name) if x == hotel[i][4]]\n",
    "        a = map(str, num)\n",
    "        b = ''.join(a)\n",
    "        hotel[i][4] = int(b)\n",
    "    if hotel[i][5] not in nat:\n",
    "        nat.append(hotel[i][5])\n",
    "        user_id = len(nat)\n",
    "    else:\n",
    "        num_2 = [p+1 for p,x in enumerate(nat) if x == hotel[i][5]]\n",
    "        c = map(str, num_2)\n",
    "        d = ''.join(c)\n",
    "        user_id = int(d)\n",
    "    hotel[i][5] = (user_id-1)*31+stay_days[i]\n",
    "    hotel[i][3] = float(hotel[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract valid data\n",
    "\n",
    "import pandas as pd\n",
    "hotel_df = pd.DataFrame.from_records(hotel[1:len(hotel)])\n",
    "hotel_df = hotel_df.loc[:,[3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data from pdDataFrame into spark DataFrame\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "mySchema = StructType([ StructField(\"Average_Score\", FloatType(), True)\\\n",
    "                       ,StructField(\"Hotel_ID\", IntegerType(), True)\\\n",
    "                       ,StructField(\"Reviewer_ID\", IntegerType(), True)])\n",
    "df = spark.createDataFrame(hotel_df,schema=mySchema)\n",
    "\n",
    "# Split data to training part and test part\n",
    "\n",
    "(training, test) = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Recommendation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "\n",
    "als = ALS(maxIter=5, regParam=0.02, userCol=\"Reviewer_ID\", itemCol=\"Hotel_ID\", \n",
    "          ratingCol=\"Average_Score\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.011005717584661975\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the model we just built; \n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Average_Score\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that the root-mean-square error is to some extent small. The behavior of the recommendation algorithm is good to believe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|Reviewer_ID|     recommendations|\n",
      "+-----------+--------------------+\n",
      "|       4900|[[157, 9.785504],...|\n",
      "|        471|[[157, 9.791729],...|\n",
      "|       1591|[[157, 9.782719],...|\n",
      "|       1342|[[157, 9.789544],...|\n",
      "|       2122|[[157, 9.780739],...|\n",
      "|       2142|[[157, 9.777184],...|\n",
      "|       1645|[[157, 9.790073],...|\n",
      "|       1088|[[157, 9.786528],...|\n",
      "|       1959|[[157, 9.7895975]...|\n",
      "|        540|[[157, 9.763406],...|\n",
      "|       1460|[[157, 9.791541],...|\n",
      "|       1990|[[157, 9.790315],...|\n",
      "|       2580|[[157, 9.802184],...|\n",
      "|       4190|[[157, 9.780701],...|\n",
      "|        392|[[157, 9.791929],...|\n",
      "|       1522|[[157, 9.779703],...|\n",
      "|        623|[[157, 9.788346],...|\n",
      "|       5614|[[157, 9.799236],...|\n",
      "|       1025|[[157, 9.785852],...|\n",
      "|       2235|[[157, 9.789667],...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|Hotel_ID|     recommendations|\n",
      "+--------+--------------------+\n",
      "|     471|[[5058, 8.131296]...|\n",
      "|    1342|[[2741, 7.5051103...|\n",
      "|     463|[[5058, 9.139458]...|\n",
      "|     833|[[5058, 7.4204326...|\n",
      "|     496|[[5058, 8.744675]...|\n",
      "|     148|[[5058, 7.631981]...|\n",
      "|    1088|[[2741, 8.905632]...|\n",
      "|    1238|[[2741, 9.0124], ...|\n",
      "|     540|[[5058, 8.945895]...|\n",
      "|    1460|[[5058, 8.227101]...|\n",
      "|     392|[[5058, 7.118697]...|\n",
      "|     243|[[5058, 9.128597]...|\n",
      "|     623|[[2741, 7.5139227...|\n",
      "|    1483|[[5058, 9.448216]...|\n",
      "|    1084|[[5058, 8.919505]...|\n",
      "|    1025|[[2741, 8.516484]...|\n",
      "|    1395|[[2741, 7.5070057...|\n",
      "|     737|[[5058, 8.641133]...|\n",
      "|     897|[[2741, 7.510787]...|\n",
      "|    1127|[[2741, 8.906633]...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 5 hotel recommendations for each user\n",
    "\n",
    "userRecs = model.recommendForAllUsers(5)\n",
    "userRecs.show()\n",
    "\n",
    "# Generate top 5 user recommendations for each hotel\n",
    "\n",
    "hotelRecs = model.recommendForAllItems(5)\n",
    "hotelRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|Reviewer_ID|     recommendations|\n",
      "+-----------+--------------------+\n",
      "|       1088|[[157, 9.786528],...|\n",
      "+-----------+--------------------+\n",
      "\n",
      "+--------+--------------------+\n",
      "|Hotel_ID|     recommendations|\n",
      "+--------+--------------------+\n",
      "|     148|[[5058, 7.631981]...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 5 hotel recommendations for a specified user\n",
    "\n",
    "user = df.select(als.getUserCol()).distinct().limit(1)\n",
    "userSubsetRecs = model.recommendForUserSubset(user, 5)\n",
    "userSubsetRecs.show()\n",
    "\n",
    "# Generate top 5 user recommendations for a specified hotel\n",
    "\n",
    "movie = df.select(als.getItemCol()).distinct().limit(1)\n",
    "movieSubSetRecs = model.recommendForItemSubset(movie, 5)\n",
    "movieSubSetRecs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With million of apps around nowadays, the following data set has become very key to getting top trending apps in iOS app store. This data set contains more than 7000 Apple iOS mobile application details. The data was extracted from the iTunes Search API at the Apple Inc website.\n",
    "\n",
    "The columns of the dataset contains:\n",
    "\n",
    "\"id\" : App ID\n",
    "\n",
    "\"track_name\": App Name\n",
    "\n",
    "\"size_bytes\": Size (in Bytes)\n",
    "\n",
    "\"currency\": Currency Type\n",
    "\n",
    "\"price\": Price amount\n",
    "\n",
    "\"rating_count_tot\": User Rating counts (for all version)\n",
    "\n",
    "\"rating_count_ver\": User Rating counts (for current version)\n",
    "\n",
    "\"user_rating\" : Average User Rating value (for all version)\n",
    "\n",
    "\"user_rating_ver\": Average User Rating value (for current version)\n",
    "\n",
    "\"ver\" : Latest version code\n",
    "\n",
    "\"cont_rating\": Content Rating\n",
    "\n",
    "\"prime_genre\": Primary Genre\n",
    "\n",
    "\"sup_devices.num\": Number of supporting devices\n",
    "\n",
    "\"ipadSc_urls.num\": Number of screenshots showed for display\n",
    "\n",
    "\"lang.num\": Number of supported languages\n",
    "\n",
    "\"vpp_lic\": Vpp Device Based Licensing Enabled\n",
    "\n",
    "Data collection date (from API); July 2017.\n",
    "\n",
    "Dimension of the data set; 7197 rows and 16 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"LogisticRegression\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=1, id=281656475, track_name='PAC-MAN Premium', size_bytes=100788224, currency='USD', price=3.99, rating_count_tot=21292, rating_count_ver=26, user_rating=4.0, user_rating_ver=4.5, ver='6.3.5', cont_rating='4+', prime_genre='Games', sup_devices.num=38, ipadSc_urls.num=5, lang.num=10, vpp_lic=1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_df = spark.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='true', inferschema='true').load('/Users/jbian/Downloads/AppleStore.csv')\n",
    "as_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- size_bytes: long (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- rating_count_tot: integer (nullable = true)\n",
      " |-- rating_count_ver: integer (nullable = true)\n",
      " |-- user_rating: double (nullable = true)\n",
      " |-- user_rating_ver: double (nullable = true)\n",
      " |-- ver: string (nullable = true)\n",
      " |-- cont_rating: string (nullable = true)\n",
      " |-- prime_genre: string (nullable = true)\n",
      " |-- sup_devices.num: integer (nullable = true)\n",
      " |-- ipadSc_urls.num: integer (nullable = true)\n",
      " |-- lang.num: integer (nullable = true)\n",
      " |-- vpp_lic: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "as_df.cache()\n",
    "as_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_c0</th>\n",
       "      <td>7197</td>\n",
       "      <td>4759.069612338474</td>\n",
       "      <td>3093.6252131502906</td>\n",
       "      <td>1</td>\n",
       "      <td>11097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>7197</td>\n",
       "      <td>8.631309974515771E8</td>\n",
       "      <td>2.7123675589291865E8</td>\n",
       "      <td>281656475</td>\n",
       "      <td>1188375727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_name</th>\n",
       "      <td>7197</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>316.7838379715733</td>\n",
       "      <td>! OH Fantastic Free Kick + Kick Wall Challenge</td>\n",
       "      <td>ｗｗｗ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_bytes</th>\n",
       "      <td>7197</td>\n",
       "      <td>1.99134453825066E8</td>\n",
       "      <td>3.592069135387029E8</td>\n",
       "      <td>589824</td>\n",
       "      <td>4025969664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>7197</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>7197</td>\n",
       "      <td>1.7262178685562626</td>\n",
       "      <td>5.833005786951921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count_tot</th>\n",
       "      <td>7197</td>\n",
       "      <td>12892.907183548701</td>\n",
       "      <td>75739.40867472602</td>\n",
       "      <td>0</td>\n",
       "      <td>2974676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count_ver</th>\n",
       "      <td>7197</td>\n",
       "      <td>460.3739057940809</td>\n",
       "      <td>3920.4551833619757</td>\n",
       "      <td>0</td>\n",
       "      <td>177050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating</th>\n",
       "      <td>7197</td>\n",
       "      <td>3.526955675976101</td>\n",
       "      <td>1.517947593629884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating_ver</th>\n",
       "      <td>7197</td>\n",
       "      <td>3.253577879672086</td>\n",
       "      <td>1.809362823117772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ver</th>\n",
       "      <td>7197</td>\n",
       "      <td>7.968864512292031</td>\n",
       "      <td>107.74333834045682</td>\n",
       "      <td>0.0.15</td>\n",
       "      <td>v3.6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont_rating</th>\n",
       "      <td>7197</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12+</td>\n",
       "      <td>9+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prime_genre</th>\n",
       "      <td>7197</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Book</td>\n",
       "      <td>Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup_devices.num</th>\n",
       "      <td>7197</td>\n",
       "      <td>37.36181742392664</td>\n",
       "      <td>3.7377152388584527</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <td>7197</td>\n",
       "      <td>3.7071001806308184</td>\n",
       "      <td>1.9860046449596336</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang.num</th>\n",
       "      <td>7197</td>\n",
       "      <td>5.43490343198555</td>\n",
       "      <td>7.919592722881359</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpp_lic</th>\n",
       "      <td>7197</td>\n",
       "      <td>0.9930526608309017</td>\n",
       "      <td>0.08306643356297923</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                    1                     2  \\\n",
       "summary           count                 mean                stddev   \n",
       "_c0                7197    4759.069612338474    3093.6252131502906   \n",
       "id                 7197  8.631309974515771E8  2.7123675589291865E8   \n",
       "track_name         7197               1824.0     316.7838379715733   \n",
       "size_bytes         7197   1.99134453825066E8   3.592069135387029E8   \n",
       "currency           7197                 None                  None   \n",
       "price              7197   1.7262178685562626     5.833005786951921   \n",
       "rating_count_tot   7197   12892.907183548701     75739.40867472602   \n",
       "rating_count_ver   7197    460.3739057940809    3920.4551833619757   \n",
       "user_rating        7197    3.526955675976101     1.517947593629884   \n",
       "user_rating_ver    7197    3.253577879672086     1.809362823117772   \n",
       "ver                7197    7.968864512292031    107.74333834045682   \n",
       "cont_rating        7197                 None                  None   \n",
       "prime_genre        7197                 None                  None   \n",
       "sup_devices.num    7197    37.36181742392664    3.7377152388584527   \n",
       "ipadSc_urls.num    7197   3.7071001806308184    1.9860046449596336   \n",
       "lang.num           7197     5.43490343198555     7.919592722881359   \n",
       "vpp_lic            7197   0.9930526608309017   0.08306643356297923   \n",
       "\n",
       "                                                               3           4  \n",
       "summary                                                      min         max  \n",
       "_c0                                                            1       11097  \n",
       "id                                                     281656475  1188375727  \n",
       "track_name        ! OH Fantastic Free Kick + Kick Wall Challenge         ｗｗｗ  \n",
       "size_bytes                                                589824  4025969664  \n",
       "currency                                                     USD         USD  \n",
       "price                                                        0.0      299.99  \n",
       "rating_count_tot                                               0     2974676  \n",
       "rating_count_ver                                               0      177050  \n",
       "user_rating                                                  0.0         5.0  \n",
       "user_rating_ver                                              0.0         5.0  \n",
       "ver                                                       0.0.15      v3.6.9  \n",
       "cont_rating                                                  12+          9+  \n",
       "prime_genre                                                 Book     Weather  \n",
       "sup_devices.num                                                9          47  \n",
       "ipadSc_urls.num                                                0           5  \n",
       "lang.num                                                       0          75  \n",
       "vpp_lic                                                        0           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|user_rating|\n",
      "+--------------------+-----------+\n",
      "|[3.99,21292.0,26....|        4.0|\n",
      "|[0.0,161065.0,26....|        4.0|\n",
      "|[0.0,188583.0,282...|        3.5|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['price','rating_count_tot', 'rating_count_ver',\n",
    "                                              'size_bytes', 'user_rating_ver'],\n",
    "                                  outputCol = 'features')\n",
    "vas_df = vectorAssembler.transform(as_df)\n",
    "vas_df = vas_df.select(['features', 'user_rating'])\n",
    "vas_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vas_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.49798538217109894]\n",
      "Intercept: 1.906138245036309\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', \n",
    "                      labelCol='user_rating', maxIter=10, regParam=0.3, \n",
    "                      elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+--------------------+\n",
      "|       prediction|user_rating|            features|\n",
      "+-----------------+-----------+--------------------+\n",
      "|1.906138245036309|        0.0|(5,[0,3],[0.99,12...|\n",
      "|1.906138245036309|        0.0|(5,[0,3],[0.99,31...|\n",
      "|1.906138245036309|        0.0|(5,[0,3],[0.99,96...|\n",
      "|1.906138245036309|        0.0|(5,[0,3],[0.99,2....|\n",
      "|1.906138245036309|        0.0|(5,[0,3],[0.99,2....|\n",
      "+-----------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.563619\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"user_rating\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"user_rating\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.00571\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that root mean squared error is 1.00159. R square is 0.55043. The closer the R square is to 1, the better fit of data the regression line is. However, the linear regression line is not so good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.477572\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'user_rating')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"user_rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE) on test data got smaller, so the regression fits data better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|          prediction|user_rating|            features|\n",
      "+--------------------+-----------+--------------------+\n",
      "|-0.00729217521636...|        0.0|(5,[0,3],[0.99,12...|\n",
      "|-0.00729217521636...|        0.0|(5,[0,3],[0.99,31...|\n",
      "|-0.00729217521636...|        0.0|(5,[0,3],[0.99,96...|\n",
      "|-0.00729217521636...|        0.0|(5,[0,3],[0.99,2....|\n",
      "|-0.00729217521636...|        0.0|(5,[0,3],[0.99,2....|\n",
      "+--------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'user_rating', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'user_rating', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.456392\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"user_rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE) on test data got smaller, so the regression got better, though not obviously.\n",
    "\n",
    "Data Source: https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is form Pima Indians Diabetes Database. The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on. The columns are as below:\n",
    "\n",
    "\n",
    "Pregnancies: Number of times pregnant;\n",
    "\n",
    "Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test;\n",
    "\n",
    "BloodPressure: Diastolic blood pressure (mm Hg);\n",
    "\n",
    "SkinThickness: Triceps skin fold thickness (mm);\n",
    "\n",
    "Insulin: 2-Hour serum insulin (mu U/ml);\n",
    "\n",
    "BMI: Body mass index (weight in kg/(height in m)^2);\n",
    "\n",
    "DiabetesPedigreeFunction: Diabetes pedigree function;\n",
    "\n",
    "Age: Age (years);\n",
    "\n",
    "Outcome: Class variable (0 or 1).\n",
    "\n",
    "The data dimension is 768 * 9.\n",
    "\n",
    "Firstly, we read it from csv into dataframe format and then save it in libsvm format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Classification\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1), Row(Pregnancies=1, Glucose=85, BloodPressure=66, SkinThickness=29, Insulin=0, BMI=26.6, DiabetesPedigreeFunction=0.351, Age=31, Outcome=0), Row(Pregnancies=8, Glucose=183, BloodPressure=64, SkinThickness=0, Insulin=0, BMI=23.3, DiabetesPedigreeFunction=0.672, Age=32, Outcome=1)]\n",
      "[LabeledPoint(1.0, [6.0,148.0,72.0,35.0,0.0,33.6,0.627,50.0]), LabeledPoint(0.0, [1.0,85.0,66.0,29.0,0.0,26.6,0.351,31.0]), LabeledPoint(1.0, [8.0,183.0,64.0,0.0,0.0,23.3,0.672,32.0])]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "\n",
    "db_df = spark.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='true', inferschema='true').load('/Users/jbian/Downloads/diabetes.csv')\n",
    "\n",
    "# Convert your dataframe in a RDD\n",
    "c = db_df.rdd \n",
    "print (c.take(3))\n",
    "\n",
    "# FROM RDD OF TUPLE TO A RDD OF LABELEDPOINT\n",
    "d = c.map(lambda line: LabeledPoint(line[8],[line[0], line[1], line[2], line[3], \n",
    "                                             line[4], line[5], line[6], line[7]]))\n",
    "print (d.take(3))\n",
    "\n",
    "# save the csv as libsvm format\n",
    "# MLUtils.saveAsLibSVMFile(d, \"/Users/jbian/Desktop/CU/6893/HW/diabetes_libsvm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.299107 \n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4174a557897a2a976e44) of depth 5 with 45 nodes\n"
     ]
    }
   ],
   "source": [
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"/Users/jbian/Desktop/CU/6893/HW/diabetes_libsvm/part-00000\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error of decision tree classifier is 0.292576, which is not low enough to be believed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "|       0.0|         0.0|(8,[0,1,2,3,4,5,6...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.290179\n",
      "GBTClassificationModel (uid=GBTClassifier_47efb8c3129493ff6113) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error of Gradient-boosted tree classifier is lower than the one we get from decision tree classifier, but I think it is still not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-432.63478504583...|[0.20615767142937...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-550.68630466658...|[0.99999973388797...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-496.25653849313...|[0.99764576046580...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-610.97441414007...|[0.99999257855435...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-490.75921658592...|[0.07912384048554...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-626.91374900256...|[0.99993988758394...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-486.79337663904...|[0.99999930098523...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-552.92547395772...|[0.99205824357932...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-556.19080373204...|[0.75907721204694...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-491.00861058176...|[0.51227873917581...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-788.45386458642...|[2.77340860414647...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-504.61981991505...|[0.96785767281382...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-417.65223252287...|[0.99549363715260...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-586.52072984752...|[0.97463147530028...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-605.33889388440...|[2.33966338320455...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-660.71563552563...|[5.30515999196824...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-748.43907029075...|[2.01916517582192...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-793.36929708924...|[1.95255285584589...|       1.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-448.64028257863...|[0.94236153348326...|       0.0|\n",
      "|  0.0|(8,[0,1,2,3,4,5,6...|[-729.83567347734...|[3.10058799486900...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.6159420289855072\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that the naive bayes method only has around 0.6 accuracy rate, which doesn't lead to good fit of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
