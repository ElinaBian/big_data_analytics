{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hadoop MapReduce vs. Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)  Both are big data frameworks, responsible for data processing;\n",
    "\n",
    "(2)  Spark doesn’t have file management, thus it relies on other file systems such as HDFS, RDBMs;\n",
    "\n",
    "(3)  Spark can do data processing in-memory; Map Reduce relies on disks;\n",
    "\n",
    "    (3.1)Spark is faster;\n",
    "   \n",
    "    (3.2)Map Reduce is able to work with larger datasets;\n",
    "   \n",
    "(4)  Hadoop uses replication for fault-tolerant, while Spark uses RDD;\n",
    "\n",
    "(5)  Spark has APIs such as SparkSQL, MLLib, GraphX, streaming;\n",
    "\n",
    "(6)  Hadoop uses Mahout for ML, which runs on top of MapReduce.\n",
    "\n",
    "### MapReduce:\n",
    "(1)  linear processing of large data sets;\n",
    "\n",
    "(2)  looking for economical solution with low speed requirements;\n",
    "\n",
    "### Spark:\n",
    "(1)  fast data processing;\n",
    "\n",
    "(2)  iterative processing;\n",
    "\n",
    "(3)  real-time analytics;\n",
    "\n",
    "(4)  graph processing.\n",
    "\n",
    "**Spark may have been more common now**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spark RDD vs. DataFrame vs. DataSet\n",
    "\n",
    "All are evaluated lazily in Spark\n",
    "\n",
    "**RDD**:\n",
    "\n",
    "(1) Has been on Spark since 1.0 release;\n",
    "\n",
    "(2) RDDs are a set of Java or Scala objects representing data;\n",
    "\n",
    "(3) If RDD is in tabular format, can be converted to DataFrame, such as by toDF();\n",
    "\n",
    "(4) Compile time type safe;\n",
    "\n",
    "(5) No built-in optimization engine.\n",
    "\n",
    "**DataFrame**:\n",
    "\n",
    "(1) Introduced in Spark 1.3 release;\n",
    "\n",
    "(2) Data organized into named columns;\n",
    "\n",
    "(3) Have optimizations using catalyst optimizer;\n",
    "\n",
    "(4) Not compile time type safe.\n",
    "\n",
    "**DataSet**:\n",
    "\n",
    "(1) Introduced in Spark 1.6 release;\n",
    "\n",
    "(2) Extension of DataFrame API;\n",
    "\n",
    "(3) Type-safe, object-oriented programming interface of RDD API;\n",
    "\n",
    "(4) Performance benefits (such as catalyst query optimizer) of DataFrame API.\n",
    "\n",
    "**RDD**:\n",
    "\n",
    "(1) Unstructured data, such as media streams;\n",
    "\n",
    "(2) Want to use low-level transformations and actions;\n",
    "\n",
    "(3) Don’t care about the schema of data.\n",
    "\n",
    "**DataFrame and DataSet**:\n",
    "\n",
    "(1) Structured or semi-structured data;\n",
    "\n",
    "(2) Want to run Hive queries;\n",
    "\n",
    "(3) Want to have optimization on performance.\n",
    "\n",
    "**Spark ML primary API is based on DataFrame**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
